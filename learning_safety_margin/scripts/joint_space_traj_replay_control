#!/usr/bin/env python3

import numpy as np
import pandas as pd
import random
import rospy
import glob
import time
import sys
import os
import state_representation as sr
from controllers import create_joint_controller, CONTROLLER_TYPE
from network_interfaces.control_type import ControlType
from network_interfaces.zmq.network import CommandMessage
from learning_safety_margin.robot_interface import RobotInterface
from learning_safety_margin.online_plotting import plot_f0_traj, plot_rec_from_replay

from sensor_msgs.msg import JointState
from std_msgs.msg import Header

def convert_joint_state_msg(state):
    # Convert sr.joint_state msg to ros JointState msg
    header = Header()
    header.stamp = rospy.get_rostime()
    #header.frame_id = state.get_reference_frame() # is this important ??
    names = state.joint_state.get_names()
    pos = state.joint_state.get_positions()
    vel = state.joint_state.get_velocities()
    effort = state.joint_state.get_torques()
    msg = JointState(header, names, pos, vel, effort)

    return msg

def find_closest_time(df, time):
    dist = (df['time'] - time).abs()
    return df.loc[dist.idxmin()]

def control_loop(fpath_list, robot, freq, do_plots):

    # create publisher
    pub = rospy.Publisher('/joint_states', JointState, queue_size=10)

    command = CommandMessage()
    command.control_type = [ControlType.EFFORT.value]

    # SET UP controller
    nb_joints = 7
    ctrl = create_joint_controller(CONTROLLER_TYPE.IMPEDANCE, nb_joints)

    ## IRL GAINS
    # ctrl.set_parameter_value("stiffness", [220, 220, 220, 180, 120, 120, 100], sr.ParameterType.DOUBLE_ARRAY)
    # ctrl.set_parameter_value("damping", [15, 15, 15, 13, 11, 10, 8], sr.ParameterType.DOUBLE_ARRAY)
    ctrl.set_parameter_value("stiffness", [220, 200, 200, 180, 120, 100, 80], sr.ParameterType.DOUBLE_ARRAY)
    ctrl.set_parameter_value("damping", [15, 15, 15, 13, 9, 8, 6], sr.ParameterType.DOUBLE_ARRAY)
    ## SIMULATOR GAINS
    # ctrl.set_parameter_value("stiffness", [10., 5., 4., 2., 2, 2, 2], sr.ParameterType.DOUBLE_ARRAY)
    # ctrl.set_parameter_value("damping", [3., 2., 2., 1., .5, .5, .5], sr.ParameterType.DOUBLE_ARRAY)
    ## FRANKALIB GAINS -- too high
    # ctrl.set_parameter_value("stiffness", [600, 600, 600, 600, 250, 150, 50], sr.ParameterType.DOUBLE_ARRAY)
    # ctrl.set_parameter_value("damping", [50, 50, 50, 50, 30, 25, 15], sr.ParameterType.DOUBLE_ARRAY)

    # SET UP variables
    desired_state = sr.JointState("franka", nb_joints)
    feedback_state = sr.JointState("franka", nb_joints)

    flag = 0
    checked_first_state = True

    # integrator variables  [60, 50, 45, 40, 35, 25, 20]
    inte_gain = [65, 55, 50, 45, 40, 30, 20]
    start_integrator_threshold = 0.3
    init_pos_err_threshold = 0.01
    integrator_reset_threshold = 0.05
    time_period = 1. / freq
    integral = np.zeros(nb_joints)
    inte_torques = np.zeros(nb_joints)

    alpha = 0.15
    dq_filtered = np.zeros(7)

    # wait a bit to receive correct state
    checked_first_state = True

    # Data recording
    recorded_state = np.zeros((10000, 1 + nb_joints * 6))* np.nan
    idx = 0

    js_record = np.zeros((10000, 1 + nb_joints * 5)) * np.nan
    js_idx = 0

    print_count = 0

    user_classification = []

    # replay path list variable
    traj_idx = 0
    traj = pd.read_pickle(fpath_list[traj_idx])
    initial_pos = traj['position'].at[0]

    rate = rospy.Rate(freq)
    while not rospy.is_shutdown():
        state = robot.get_state()

        if not state:
            continue

        # Wait a bit so state is correct
        elif state and checked_first_state:
            print("EEF position: ", state.ee_state.get_position())
            rospy.sleep(0.1)
            checked_first_state = False
            input("Waiting for user input... Press Enter to start")
            print("Going to start position...")
            start_f0 = time.time()
            continue


        if flag == 0:
            # ------GO TO START POSITION ------------------------

            error = abs(initial_pos - state.joint_state.get_positions())
            time_f0 = time.time() - start_f0

            if all(error < init_pos_err_threshold):
                print("Error :", error)
                print("Reached start position in %s seconds" % time_f0)
                flag = 1

                # Stop robot
                command.joint_state = state.joint_state
                command.joint_state.set_torques(np.zeros(7))
                robot.send_command(command)

                ## plot f0 traj
                # remove zeros
                js_record = js_record[~np.isnan(js_record).any(axis=1)]
                if do_plots:
                    plot_f0_traj(js_record)

                input("Waiting for user input... Press Enter to start \n ")
                rospy.sleep(0.3)
                print("Replaying trajectory %s of %s " % (traj_idx+1, len(fpath_list)))
                print("Traj name : ", fn_list[traj_idx])
                timeZero = time.time()
                continue

            # Adding integrator when getting close to target
            if np.all(error < start_integrator_threshold):
                # print("Adding integrator for precise positioning")
                integral += (initial_pos - state.joint_state.get_positions()) * time_period

                # reset integral if overhsoot
                if np.any(abs(integral) > integrator_reset_threshold):
                    integral *= 0
                    print("RESET INTEGRAL \n")

                inte_torques = inte_gain * integral

                if print_count % 100 == 0:
                    print("INTERGRATOR TORQUES :", inte_torques)

            # Extract form Yang code
            feedback_state.set_positions(state.joint_state.get_positions())
            dq_filtered = alpha * dq_filtered +  (1 - alpha)* state.joint_state.get_velocities()
            feedback_state.set_velocities(dq_filtered)

            velo_d = initial_pos - state.joint_state.get_positions()

            # NOTE: this might cause error
            velo_d = velo_d / np.linalg.norm(velo_d) if np.linalg.norm(velo_d) > 1.0 else velo_d
            desired_state.set_velocities(velo_d)

            pos_d = feedback_state.get_positions() + time_period * velo_d
            desired_state.set_positions(pos_d)

            ## DEBUG PRINTS
            # print("Joint positions: ", feedback_state.get_positions())
            # print("Joint Velocities: ", feedback_state.get_velocities())
            # print("Desired positions: ", desired_state.get_positions())
            # print("Desired Velocities: ", desired_state.get_velocities())

            command_torques = sr.JointTorques(ctrl.compute_command(desired_state, feedback_state))
            command.joint_state = state.joint_state
            command.joint_state.set_torques(command_torques.get_torques() + inte_torques)

            # record data for plots
            js_record[js_idx, 0] = time_f0
            js_record[js_idx, 1:8] = state.joint_state.get_positions()
            js_record[js_idx, 8:15] = state.joint_state.get_velocities()
            js_record[js_idx, 15:22] = initial_pos
            js_record[js_idx, 22:29] = integral
            js_record[js_idx, 29:36] = inte_torques
            js_idx += 1
            print_count +=1

            # print("Command:", command.joint_state.get_torques())
            if np.any(command_torques.get_torques() > 30):
                print("TORQUES TOO BIG !!!")
                break

            else :
                robot.send_command(command)

        elif flag == 1:
            #-------FOLLOW TRAJECTORY ---------------------

            # GET current time
            nIter_time = time.time() - timeZero
            # print("Time : ", round(nIter_time,4))

            # Check if reached end of traj
            if nIter_time > traj['time'].iat[-1]:
                print("REACHED END OF TRAJ")
                error = np.linalg.norm(traj['position'].iat[-1] - state.joint_state.get_positions())
                print("DISTANCE TO TARGET : ", error)

                flag = 2

                # Stop robot
                command.joint_state = state.joint_state
                command.joint_state.set_torques(np.zeros(7))
                robot.send_command(command)

                print("WAIT ...")
                rospy.sleep(0.5)
                continue

            ## Feedback state
            feedback_state.set_positions(state.joint_state.get_positions())
            # filter velocities
            dq_filtered = alpha * dq_filtered + (1-alpha) * state.joint_state.get_velocities()
            feedback_state.set_velocities(dq_filtered)

            ## Get desired state from traj
            df_desired = find_closest_time(traj, nIter_time)

            desired_state.set_positions(df_desired['position'])
            desired_state.set_velocities(df_desired['velocity'])

            ## DEBUG prints
            # print("Joint positions: ", feedback_state.get_positions())
            # print("Joint Velocities: ", feedback_state.get_velocities())
            # print("Desired positions: ", desired_state.get_positions())
            # print("Desired Velocities: ", desired_state.get_velocities())

            # SAVE current state
            recorded_state[idx, 0] = nIter_time
            recorded_state[idx, 1:8] = state.joint_state.get_positions()
            recorded_state[idx, 8:15] = state.joint_state.get_velocities()
            recorded_state[idx, 15:22] = state.joint_state.get_torques()
            recorded_state[idx, 22:29] = df_desired['position']
            recorded_state[idx, 29:36] = df_desired['velocity']
            recorded_state[idx, 36:43] = df_desired['torques']
            idx += 1

            # Set command torques
            command_torques = sr.JointTorques(ctrl.compute_command(desired_state, feedback_state))
            command.joint_state = state.joint_state
            command.joint_state.set_torques(command_torques.get_torques())

            if np.any(command_torques.get_torques() > 30):
                print("TORQUES TOO BIG !!!")
                print("Command:", command.joint_state.get_torques())
                break

            else:
                robot.send_command(command)

        if flag == 2:
            # ------------END OF TRAJ-> DO PLOTS ------------------------
            # remove zeros
            recorded_state = recorded_state[~np.isnan(recorded_state).any(axis=1)]

            # save file, reuse same name
            complete_fn = os.path.split(fpath_list[traj_idx])
            safe_category = os.path.basename(os.path.normpath(complete_fn[0]))
            fn = os.path.splitext(complete_fn[1])
            save_fn = os.path.join(save_dir, safe_category, fn[0] + "_replay")
            np.save(save_fn, recorded_state, allow_pickle=False)

            # option to replay the same trajectory again
            should_replay = input("Do you want to replay this trajectory again ? [y/n] \n")

            if should_replay == 'n':

                # Get user classification
                classified_as = input("How would you classify this trajectory ? [safe/daring/unsafe] \n")
                user_classification.append(classified_as)
                print("Classified as :", classified_as)

                np.savetxt(save_dir + "temp_list_of_labels.txt", np.array(user_classification), fmt='%s')

                print("Setting up next trajectory... \n")
                ## Set up next traj
                if traj_idx < (len(fpath_list)-1):
                    traj_idx += 1
                else:
                    print("PLAYED ALL TRAJECTORIES IN LIST \n")
                    # Save names of replayed trajectories with corresponding labels
                    dict2save = {'Replayed demo': fn_list, 'User Label': user_classification}
                    df = pd.DataFrame.from_dict(dict2save)
                    df.to_csv(save_dir+"Replayed_demos_and_labels.csv", index=False, header=True)
                    os.remove(save_dir + "temp_list_of_labels.txt")
                    os.remove(save_dir + "temp_list_of_replayed_trajectories.txt")

                    # call plot function
                    if do_plots:
                        plot_rec_from_replay(traj, recorded_state, fn_list[traj_idx])

                if do_plots:
                    plot_rec_from_replay(traj, recorded_state, fn_list[traj_idx-1])

                traj = pd.read_pickle(fpath_list[traj_idx])
                initial_pos = traj['position'].at[0]

            elif should_replay == 'y':
                print("Replaying same trajectory... \n")

            # Reset recording list
            recorded_state = np.zeros((10000, 1 + nb_joints * 6)) * np.nan
            idx = 0
            js_record = np.zeros((10000, 1 + nb_joints * 5)) * np.nan
            js_idx = 0

            # Reset integrator
            integral = np.zeros(7)

            # Reset flag to start loop again
            input("Waiting for user input... Press Enter to start")
            print("Going to start position...")
            start_f0 = time.time()
            flag = 0

        # Publish joint states for recording
        pub.publish(convert_joint_state_msg(state))

        rate.sleep()


# Controller to replay demonstrations
if __name__ == '__main__':

    rospy.init_node("test", anonymous=True)

    # Check passed argument - User number
    if len(sys.argv) >= 2:
        user_number = sys.argv[1]
        number_of_traj = sys.argv[2]
    else:
        user_number = '0'
        number_of_traj = '2'

    if isinstance(user_number, str):
        print("Processing rosbags for User_" + user_number)

    # Variables
    freq = 200
    do_plots = False

    # Set up directories
    data_dir = "/home/ros/ros_ws/src/learning_safety_margin/data/User_"+user_number+"/"
    save_dir = data_dir + "replays/"
    if not os.path.isdir(save_dir):
        os.mkdir(save_dir)

    # Make list of trajectories
    traj_nbr_per_category = int(number_of_traj)
    category_list = ["safe/", "daring/", "unsafe/"]
    fpath_list = []

    for category in category_list:

        ## count nbr of traj in category folder, make a list
        all_fn = glob.glob(data_dir + "csv/" + category + "*.pkl")

        # Set save dir and create folder if needed
        cat_save_dir = save_dir + category
        if not os.path.isdir(cat_save_dir):
            os.mkdir(cat_save_dir)

        # Sample trajectories from category
        fpath_list.append(random.sample(all_fn, traj_nbr_per_category))

    # Reshape list to be 1D, then shuffle
    fpath_list = sum(fpath_list, [])
    random.shuffle(fpath_list)

    # Save name and category of each traj in a txt file
    fn_list = [os.path.join(os.path.basename(os.path.normpath(os.path.split(fn)[0])), os.path.splitext(os.path.split(fn)[1])[0]) for fn in fpath_list]
    print(fn_list)
    np.savetxt(save_dir + "temp_list_of_replayed_trajectories.txt", np.array(fn_list), fmt='%s')

    print("Going to start position...")
    robot_interface = RobotInterface("*:1701", "*:1702")
    control_loop(fpath_list, robot_interface, freq, do_plots)

